{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å‰é¦ˆç¥ç»ç½‘ç»œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„å·¥å…·åŒ…\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# ç»˜ç”»æ—¶ä½¿ç”¨çš„å·¥å…·åŒ…\n",
    "import matplotlib.pyplot as plt\n",
    "# å½“åœ¨notebookä¸­è¿è¡Œæ—¶ï¼Œè¯·é”®å…¥ä»¥ä¸‹ä»£ç ï¼Œå›¾ç‰‡å¯ä»¥åœ¨å•å…ƒæ ¼ä¸­è¾“å‡ºï¼Œåœ¨ç¼–è¯‘å™¨ä¸­è¿è¡Œæ—¶ä¸éœ€è¦\n",
    "%matplotlib inline\n",
    "# å¯¼å…¥é¸¢å°¾èŠ±æ•°æ®é›†\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‡€æ´»æ€§å€¼\n",
    "\n",
    "å‡è®¾ä¸€ä¸ªç¥ç»å…ƒæ¥æ”¶ ğ· ä¸ªè¾“å…¥ğ‘¥1 , ğ‘¥2 , â‹¯ , ğ‘¥ğ·ï¼Œä»¤å‘é‡ğ’™ = [ğ‘¥1 ; ğ‘¥2 ; â‹¯ ; ğ‘¥ğ·]æ¥è¡¨ç¤ºè¿™ç»„è¾“å…¥ï¼Œå¹¶ç”¨å‡€æ´»æ€§å€¼ ğ‘§ è¡¨ç¤ºä¸€ä¸ªç¥ç»å…ƒæ‰€è·å¾—çš„è¾“å…¥ä¿¡å·ğ’™çš„åŠ æƒå’Œã€‚\n",
    "ä¸ºäº†æé«˜æ•ˆç‡ï¼Œé€šå¸¸ä¼šå°†N  (N>1) ä¸ªæ ·æœ¬å½’ä¸ºä¸€ç»„è¿›è¡Œæˆæ‰¹é¢„æµ‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x è¡¨ç¤ºä¸¤ä¸ªå«æœ‰5ä¸ªç‰¹å¾çš„æ ·æœ¬ï¼Œxæ˜¯ä¸€ä¸ªäºŒç»´çš„tensor\n",
    "x = torch.randn((2,5))\n",
    "# w è¡¨ç¤ºå«æœ‰5ä¸ªå‚æ•°çš„æƒé‡å‘é‡ï¼Œwæ˜¯ä¸€ä¸ªäºŒç»´çš„tensor\n",
    "w = torch.randn((5,1))\n",
    "# åç½®é¡¹ï¼Œbæ˜¯ä¸€ä¸ªäºŒç»´çš„tensorï¼Œä½†båªæœ‰ä¸€ä¸ªæ•°å€¼\n",
    "b = torch.randn((1,1))\n",
    "# çŸ©é˜µä¹˜æ³•ï¼Œè¯·æ³¨æ„ x å’Œ w çš„é¡ºåºï¼Œä¸ b ç›¸åŠ æ—¶ä½¿ç”¨äº†å¹¿æ’­æœºåˆ¶\n",
    "z = torch.matmul(x, w) + b\n",
    "# å¦ä¸€ç§å†™æ³•\n",
    "z_2 = x@w + b \n",
    "# æ‰“å°ç»“æœï¼Œzæ˜¯ä¸€ä¸ªäºŒç»´çš„tensorï¼Œè¡¨ç¤ºä¸¤ä¸ªæ ·æœ¬ç»è¿‡ç¥ç»å…ƒåçš„å„è‡ªå‡€æ´»æ€§å€¼\n",
    "print('output z:' , z)\n",
    "print('shape of z: ', z.shape)\n",
    "print('output z_2:', z_2)\n",
    "print('shape of z:', z_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç®€æ´å®ç°ï¼Œä½¿ç”¨PyTorchæä¾›çš„ç±»ã€‚è¯·ç‰¢è®°å‚æ•°çš„å®é™…æ„ä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®ä¾‹åŒ–ä¸€ä¸ªçº¿æ€§å±‚ï¼Œæ¥å—è¾“å…¥ç»´åº¦æ˜¯5ï¼Œè¾“å‡ºç»´åº¦æ˜¯1\n",
    "net = nn.Linear(5,1)\n",
    "z_3 = net(x)\n",
    "# æ‰“å°ç»“æœï¼Œz2çš„å½¢çŠ¶ä¸zä¸€æ ·ï¼Œå«ä¹‰ä¹Ÿä¸zä¸€æ ·\n",
    "print('output z2: ', z_3)\n",
    "print('shape of z2:' , z_3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¿€æ´»å‡½æ•°\n",
    "\n",
    "å‡€æ´»æ€§å€¼åœ¨ç»è¿‡ä¸€ä¸ªéçº¿æ€§å‡½æ•°ğ‘“(â‹…)åï¼Œå¾—åˆ°ç¥ç»å…ƒçš„æ´»æ€§å€¼ğ‘ï¼Œä¹Ÿå°±æ˜¯è¯¥å±‚ç¥ç»å…ƒçš„è¾“å‡ºã€‚\n",
    "\n",
    "æ¿€æ´»å‡½æ•°é€šå¸¸ä¸ºéçº¿æ€§å‡½æ•°ï¼Œå¸¸ç”¨çš„æœ‰Sigmoidå‹æ¿€æ´»å‡½æ•°å’ŒReLUæ¿€æ´»å‡½æ•°ï¼Œè¦æƒ³å®ç°ä»–ä»¬ï¼Œå…¶å®éå¸¸çš„ç®€å•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic å‡½æ•°\n",
    "def logistic(z):\n",
    "    return 1.0 / (1.0 + torch.exp(-z))\n",
    "# Tanhå‡½æ•°\n",
    "def tanh(z):\n",
    "    return (torch.exp(z) - torch.exp(-z)) / (torch.exp(z) + torch.exp(-z))\n",
    "# ReLUå‡½æ•°\n",
    "def relu(z):\n",
    "    return torch.max(z, torch.zeros_like(z))\n",
    "# leakyReLUå‡½æ•°\n",
    "def leaky_relu(z, gamma=0.1):\n",
    "    positive = torch.max(z, torch.zeros_like(z))\n",
    "    negative = torch.min(z, torch.zeros_like(z))\n",
    "    return positive + gamma * negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”»å‡ºæ¿€æ´»å‡½æ•°çš„å›¾åƒ\n",
    "# ä»-10 åˆ° 10 æ¯é—´éš”0.01 å–ä¸€ä¸ªæ•°\n",
    "a = torch.arange(-10, 10, 0.01)\n",
    "plt.figure()\n",
    "# åœ¨ç¬¬ä¸€ä¸ªå­å›¾ä¸­ç»˜åˆ¶Sigmoidå‹æ¿€æ´»å‡½æ•°\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(a.tolist(), logistic(a).tolist(), color= 'red', label='logistic')\n",
    "plt.plot(a.tolist(), tanh(a).tolist(), color='blue', linestyle='--', label='tanh')\n",
    "# åœ¨ç¬¬äºŒä¸ªå­å›¾ä¸­ç»˜åˆ¶ReLUå‹æ¿€æ´»å‡½æ•°\n",
    "plt.subplot(222)\n",
    "plt.plot(a.tolist(), relu(a).tolist(), color='g', label='relu')\n",
    "plt.plot(a.tolist(), leaky_relu(a).tolist(), color='black',linestyle='--', label='leaky relu')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç®€æ´å®ç°ï¼Œä½¿ç”¨PyTorchæä¾›çš„æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zä¸ºå‰é¢è®¡ç®—çš„å‡€æ´»æ€§å€¼\n",
    "sig_output = torch.sigmoid(z)\n",
    "tan_output = torch.tanh(z)\n",
    "relu_output = torch.relu(z)\n",
    "# æ‰“å°è¾“å‡ºç»“æœ\n",
    "print('sigmoid:',sig_output)\n",
    "print('tanh:', tan_output)\n",
    "print('ReLU:', relu_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŸºäºå‰é¦ˆç¥ç»ç½‘ç»œçš„äºŒåˆ†ç±»ä»»åŠ¡\n",
    "\n",
    "æƒ³è¦å®Œæˆä¸€ä¸ªæ·±åº¦å­¦ä¹ çš„ä»»åŠ¡,å¯ä»¥ç®€å•åœ°å°†å…¶åˆ†ä¸º7æ­¥ï¼Œæ„å»ºæ•°æ®é›†ã€æ„å»ºæ¨¡å‹ã€è®¾è®¡æŸå¤±å‡½æ•°ã€æ ¹æ®æŸå¤±å‡½æ•°æ¨¡å‹è®­ç»ƒé˜¶æ®µã€è®­ç»ƒåŒæ—¶çš„æµ‹è¯•é˜¶æ®µã€è®­ç»ƒç»“æœå±•ç¤ºã€é¢„æµ‹é˜¶æ®µï¼›å…¶ä¸­å‰4æ­¥æ˜¯ä¸å¯ç¼ºå°‘çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çº¿æ€§å±‚ç®—å­ï¼Œè¯·ä¸€å®šæ³¨æ„ç»§æ‰¿è‡ª nn. Module, è¿™ä¼šå¸®ä½ è§£å†³è®¸å¤šç»†èŠ‚ä¸Šçš„é—®é¢˜\n",
    "class Linear(nn.Module): \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Linear, self).__init__()\n",
    "        self.params = {}\n",
    "        self.params['W'] = nn.Parameter(torch.randn(input_size, output_size, requires_grad=True))\n",
    "        self.params['b'] = nn.Parameter(torch.randn(1, output_size, requires_grad=True))\n",
    "        self.grads = {}\n",
    "        self.inputs = None\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        outputs = torch.matmul(inputs, self.params['W']) + self.params['b']\n",
    "        return outputs\n",
    "    \n",
    "# å®ç°ä¸€ä¸ªä¸¤å±‚çš„å‰é¦ˆç¥ç»ç½‘ç»œ\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super( MLP, self).__init__()\n",
    "        self.fc1 = Linear(input_size, hidden_size)\n",
    "        self.fc2 = Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z1 = self.fc1(x)\n",
    "        a1 = logistic(z1)\n",
    "        z2 = self.fc2(a1)\n",
    "        a2 = logistic(z2)\n",
    "        return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.ones((1,10))\n",
    "input_size, hidden_size, output_size = 10, 5, 2\n",
    "net = MLP(input_size, hidden_size, output_size)\n",
    "output = net(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æŸå¤±å‡½æ•°ï¼Œå¯¹äºåˆ†ç±»é—®é¢˜ï¼Œå¸¸ä½¿ç”¨äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°\n",
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯·æ·±åˆ»ç†è§£è¿™ç§è¡¨è¾¾å½¢å¼ã€‚\n",
    "# yçš„å«ä¹‰æ˜¯ï¼Œç¬¬ä¸€ä¸ªæ ·æœ¬æ˜¯ç¬¬1ç±»ï¼Œç¬¬äºŒä¸ªæ ·æœ¬æ˜¯ç¬¬3ç±»ï¼›\n",
    "# y_hatçš„å«ä¹‰æ˜¯ï¼Œæ¨¡å‹é¢„æµ‹ç¬¬ä¸€ä¸ªæ ·æœ¬å±äºä¸åŒç±»çš„ç½®ä¿¡åº¦åˆ†åˆ«æ˜¯0.1ã€0.3å’Œ0.6ï¼Œæ¨¡å‹é¢„æµ‹ç¬¬äºŒä¸ªæ ·æœ¬å±äºä¸åŒç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†åˆ«æ˜¯0.3ã€0.2ã€0.5\n",
    "\n",
    "y = torch.tensor([0, 2])\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "\n",
    "cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åå‘ä¼ æ’­ç®—æ³•\n",
    "\n",
    "æˆªæ­¢åˆ°ç›®å‰ï¼Œä½ åº”è¯¥å¯¹ç¥ç»ç½‘ç»œçš„å‰å‘è¿‡ç¨‹æœ‰äº†ä¸€å®šçš„ç†è§£ï¼Œä½†æˆ‘ä»¬å®ç°çš„æ¿€æ´»å‡½æ•°å’ŒæŸå¤±å‡½æ•°è¿˜éƒ½ä¸æ”¯æŒåå‘ä¼ æ’­ã€‚\n",
    "æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬åŠ å…¥è¿™ä¸ªåŠŸèƒ½ã€‚ç¥ç»ç½‘ç»œç›¸å½“äºä¸€ä¸ªå¤åˆå‡½æ•°ï¼Œéœ€è¦åˆ©ç”¨é“¾å¼æ³•åˆ™è¿›è¡Œåå‘ä¼ æ’­æ¥è®¡ç®—æ¢¯åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropyLoss():\n",
    "    def __init__(self, model):\n",
    "        self.predicts = None\n",
    "        self.labels = None\n",
    "        self.num = None\n",
    "        self.model = model\n",
    "        \n",
    "    def __call__(self, predicts, labels):\n",
    "        return self.forward(predicts, labels)\n",
    "    \n",
    "    def forward(self, predicts, labels):\n",
    "        self.predicts = predicts\n",
    "        self.labels = labels\n",
    "        self.num = self.predicts.shape[0]\n",
    "        loss = - torch.log(y_hat[range(len(y_hat)), y])\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        \n",
    "        inputs_grads = -1 * (self.labels/self.predicts - (1 - self.labels)/(1 - self.predicts))/self.num\n",
    "        \n",
    "        self.model.backward(inputs_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic():\n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "        self.params = None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs =  1.0 / (1.0 + torch.exp(-inputs))\n",
    "        self.outputs = outputs\n",
    "        return outputs\n",
    "    \n",
    "    def backward(self, outputs_grads=None):\n",
    "        if outputs_grads is None:\n",
    "            outputs_grads = torch.ones(self.outputs.shape)\n",
    "        outputs_grad_inputs = torch.multiply(self.outputs, (1.0 - self.outputs))\n",
    "        return torch.multiply(outputs_grads, outputs_grad_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = Logistic()\n",
    "x = torch.tensor([3,3,4,2])\n",
    "y = act(x)\n",
    "\n",
    "z = act.backward()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.params = {}\n",
    "        self.params['W'] = nn.Parameter(torch.randn(input_size, output_size, requires_grad=True))\n",
    "        self.params['b'] = nn.Parameter(torch.randn(1, output_size, requires_grad=True))\n",
    "        self.inputs = None\n",
    "        self.grads = {}\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        outputs = torch.matmul(self.inputs, self.params['W']) + self.params['b']\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def backward(self, grads=None):\n",
    "        if grads == None:\n",
    "            grads = torch.ones(self.params['W'].shape)\n",
    "        self.grads['w'] = torch.matmul(self.inputs.T, grads)\n",
    "        self.grads['b'] = torch.sum(grads, dim=0)\n",
    "        return torch.matmul(grads, self.params['W'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Linear(4, 2)\n",
    "x = torch.tensor([1,1,1,1], dtype=torch.float32)\n",
    "y = net(x)\n",
    "z = net.backward()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªåŠ¨æ±‚å¯¼\n",
    "\n",
    "PyTorchä¸­ï¼Œæ‰€æœ‰ç¥ç»ç½‘ç»œçš„æ ¸å¿ƒæ˜¯ autograd åŒ…ã€‚autogradåŒ…ä¸ºå¼ é‡ä¸Šçš„æ‰€æœ‰æ“ä½œæä¾›äº†è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ã€‚å®ƒæ˜¯ä¸€ä¸ªåœ¨è¿è¡Œæ—¶å®šä¹‰ ( define-by-run ï¼‰çš„æ¡†æ¶ï¼Œè¿™æ„å‘³ç€åå‘ä¼ æ’­æ˜¯æ ¹æ®ä»£ç å¦‚ä½•è¿è¡Œæ¥å†³å®šçš„ï¼Œå¹¶ä¸”æ¯æ¬¡è¿­ä»£å¯ä»¥æ˜¯ä¸åŒçš„ã€‚\n",
    "\n",
    "æ¯ä¸ªå¼ é‡éƒ½æœ‰ä¸€ä¸ª.grad_fnå±æ€§ï¼Œè¯¥å±æ€§å¼•ç”¨äº†åˆ›å»º Tensor è‡ªèº«çš„Function(é™¤éè¿™ä¸ªå¼ é‡æ˜¯ç”¨æˆ·æ‰‹åŠ¨åˆ›å»ºçš„ï¼Œå³è¿™ä¸ªå¼ é‡çš„grad_fnæ˜¯ None )ã€‚ä¸‹é¢ç»™å‡ºçš„ä¾‹å­ä¸­ï¼Œå¼ é‡ç”±ç”¨æˆ·æ‰‹åŠ¨åˆ›å»ºï¼Œå› æ­¤grad_fnè¿”å›ç»“æœæ˜¯Noneã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€ç®€å•çš„æƒ…å†µï¼ŒXæ˜¯ä¸€ä¸ªæ ‡é‡\n",
    "x = torch.tensor(2, dtype=torch.float32, requires_grad=True)\n",
    "y = x ** 2 + 4 * x \n",
    "print(x.grad)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœ Tensor æ˜¯ä¸€ä¸ªæ ‡é‡(å³å®ƒåŒ…å«ä¸€ä¸ªå…ƒç´ çš„æ•°æ®ï¼‰ï¼Œåˆ™ä¸éœ€è¦ä¸º backward() æŒ‡å®šä»»ä½•å‚æ•°ï¼Œä½†æ˜¯å¦‚æœå®ƒæœ‰æ›´å¤šçš„å…ƒç´ ï¼Œåˆ™éœ€è¦æŒ‡å®šä¸€ä¸ªgradientå‚æ•°ï¼Œè¯¥å‚æ•°æ˜¯å½¢çŠ¶åŒ¹é…çš„å¼ é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "# yæ˜¯ä¸€ä¸ªçŸ©é˜µ\n",
    "y = x ** 2 + 4 * x\n",
    "y.backward(torch.ones(2, 2))\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = x ** 3 + 2 * x\n",
    "# zæ˜¯ä¸€ä¸ªæ ‡é‡\n",
    "z = u.sum()\n",
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®è·µ\n",
    "\n",
    "   åœ¨ä¹‹å‰å®ç°çš„ä»£ç ä¸­ï¼Œå€ŸåŠ©æ·±åº¦å­¦ä¹ æ¡†æ¶çš„å¸®åŠ©ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†å¤§éƒ¨åˆ†åŠŸèƒ½ã€‚åœ¨æœ€åçš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å¼•å…¥å°æ‰¹é‡å’Œéšæœºæ¢¯åº¦ä¸‹é™æ³•ï¼Œå³æ¯æ¬¡ä»…æ ¹æ®æ•°æ®é›†ä¸€ä¸ªæ‰¹é‡å¤§å°çš„æ•°æ®æ¥æ›´æ–°å‚æ•°ã€‚\n",
    "   ä¸ºäº†ä½¿ç”¨å°æ‰¹é‡ï¼Œé€šå¸¸çš„åšæ³•æ˜¯æ„å»ºä¸€ä¸ªæ•°æ®è¿­ä»£å™¨,åœ¨æ¯æ¬¡è¿­ä»£æ—¶ä»å…¨éƒ¨æ•°æ®é›†ä¸­è·å–æŒ‡å®šæ•°é‡çš„æ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥å€ŸåŠ©æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­çš„Datasetç±»å’ŒDataLoaderç±»æ¥å®ç°æ­¤åŠŸèƒ½ã€‚\n",
    "   éšæœºæ¢¯åº¦ä¸‹é™æ³•åˆ™å®Œå…¨å¼•ç”¨æ·±åº¦å­¦ä¹ æ¡†æ¶å·²ç»å®ç°å¥½çš„æ–¹æ³•ã€‚\n",
    "   åœ¨ç»§æ‰¿Datasetç±»æ—¶ï¼Œåº”å®ç°\\_\\_getitem\\_\\_å’Œ\\_\\_len\\_\\_ä¸¤ä¸ªæ–¹æ³•ï¼Œå‰è€…ä¼šæ ¹æ®ç´¢å¼•è·å–æ•°æ®é›†ä¸­æŒ‡å®šçš„æ ·æœ¬ï¼Œåè€…åˆ™è¿”å›æ•°æ®é›†æ ·æœ¬çš„ä¸ªæ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ­¤å‡½æ•°ç”¨äºåŠ è½½é¸¢å°¾èŠ±æ•°æ®é›†\n",
    "def load_data(shuffle=True):\n",
    "    x = torch.tensor(load_iris().data)\n",
    "    y = torch.tensor(load_iris().target)\n",
    "    \n",
    "    # æ•°æ®å½’ä¸€åŒ–\n",
    "    x_min = torch.min(x, dim=0).values\n",
    "    x_max = torch.max(x, dim=0).values\n",
    "    x = (x-x_min)/(x_max-x_min)\n",
    "    \n",
    "    if shuffle:\n",
    "        idx = torch.randperm(x.shape[0])\n",
    "        x = x[idx]\n",
    "        y = y[idx]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºè‡ªå·±çš„æ•°æ®é›†,ç»§æ‰¿è‡ªDatasetç±»\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, mode='train', num_train=120, num_dev=15):\n",
    "        super(IrisDataset,self).__init__()\n",
    "        x, y = load_data(shuffle=True)\n",
    "        if mode == 'train':\n",
    "            self.x, self.y = x[:num_train], y[:num_train]\n",
    "        elif mode == 'dev':\n",
    "            self.x, self.y = x[num_train:num_train + num_dev], y[num_train:num_train + num_dev]\n",
    "        else:\n",
    "            self.x, self.y = x[num_train + num_dev:], y[num_train + num_dev:]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®ä¾‹åŒ–æ•°æ®é›†å,ä½¿ç”¨DataLoaderè¿›è¡Œå°è£….ä¸ºç®€ä¾¿å¯ä½¿æ•°æ®é›†æ ·æœ¬æ€»æ•°ä¸ºæ‰¹é‡å¤§å°çš„æ•´æ•°å€,ä½†å®é™…å¹¶ä¸å¼ºåˆ¶è¦æ±‚;shuffleå‚æ•°çš„å«ä¹‰æ˜¯æ˜¯å¦éšæœºä»æ•°æ®é›†ä¸­å–æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# åˆ†åˆ«æ„å»ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†\n",
    "train_dataset = IrisDataset(mode='train')\n",
    "dev_dataset = IrisDataset(mode='dev')\n",
    "test_dataset = IrisDataset(mode='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®Œå…¨ä¾é æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ„å»ºä¸€ä¸ªç®€å•çš„ä¸¤å±‚å‰é¦ˆç¥ç»ç½‘ç»œï¼Œè¾“å…¥å±‚ç¥ç»å…ƒä¸ªæ•°ä¸º4ï¼Œè¾“å‡ºå±‚ç¥ç»å…ƒä¸ªæ•°ä¸º3ï¼Œéšå«å±‚ç¥ç»å…ƒä¸ªæ•°ä¸º6ã€‚\n",
    "è¿™ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œå’Œæˆ‘ä»¬åœ¨å‰é¢å®ç°çš„MLPç±»æœ€å¤§çš„åŒºåˆ«åœ¨äºï¼Œæˆ‘ä»¬å®ç°ç±»ä¸­ä½¿ç”¨äº†è‡ªå·±å†™çš„æ¿€æ´»å‡½æ•°ï¼Œè¯¥æ¿€æ´»å‡½æ•°ä¸èƒ½é€šè¿‡åå‘ä¼ æ’­æ›´æ–°å‚æ•°ï¼Œä½†æ·±åº¦å­¦ä¹ æ¡†æ¶å·²ç»å¸®æˆ‘ä»¬å®Œæˆäº†è¿™ä¸ªåŠŸèƒ½ã€‚ï¼ˆå…¶å®é€šè¿‡ç®€å•çš„æ”¹åŠ¨ï¼Œæˆ‘ä»¬çš„æ¿€æ´»å‡½æ•°ä¹Ÿå¯ä»¥åä¼ æ¢¯åº¦ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FeedForward,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.act = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.fc1(inputs)\n",
    "        outputs = self.act(outputs)\n",
    "        outputs = self.fc2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®ç°ç¬¬ä¸€ä¸ªè¾…åŠ©åŠŸèƒ½â€”â€”è®¡ç®—é¢„æµ‹çš„å‡†ç¡®ç‡ã€‚Accuracyæ”¯æŒå¯¹æ¯ä¸€ä¸ªå›åˆä¸­æ¯æ‰¹æ•°æ®è¿›è¡Œè¯„ä»·ï¼Œå¹¶å°†ç»“æœç´¯ç§¯ï¼Œæœ€ç»ˆè·å¾—æ•´æ‰¹æ•°æ®çš„è¯„ä»·ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ”¯æŒåˆ†æ‰¹è¿›è¡Œæ¨¡å‹è¯„ä»·çš„ Accuracy ç±»\n",
    "class Accuracy:\n",
    "    def __init__(self, is_logist=True):\n",
    "        # æ­£ç¡®æ ·æœ¬ä¸ªæ•°\n",
    "        self.num_correct = 0\n",
    "        # æ ·æœ¬æ€»æ•°\n",
    "        self.num_count = 0\n",
    "        self.is_logist = is_logist\n",
    "    \n",
    "    def update(self, outputs, labels):\n",
    "        # åˆ¤æ–­æ˜¯å¦ä¸ºäºŒåˆ†ç±»ä»»åŠ¡\n",
    "        if outputs.shape[1] == 1:\n",
    "            outputs = outputs.squeeze(-1)\n",
    "            # åˆ¤æ–­æ˜¯å¦æ˜¯logitå½¢å¼çš„é¢„æµ‹å€¼\n",
    "            if self.is_logist:\n",
    "                preds = (outputs >= 0).long()\n",
    "            else:\n",
    "                preds = (preds >= 0.5).long()\n",
    "        else:\n",
    "            # å¤šåˆ†ç±»ä»»åŠ¡æ—¶ï¼Œè®¡ç®—æœ€å¤§å…ƒç´ ç´¢å¼•ä½œä¸ºç±»åˆ«\n",
    "            preds = torch.argmax(outputs, dim=1).long()\n",
    "            \n",
    "        # è·å–æœ¬æ‰¹æ•°æ®ä¸­é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬ä¸ªæ•°\n",
    "        labels = labels.squeeze(-1)\n",
    "        batch_correct = (preds==labels).float().sum()\n",
    "        batch_count = len(labels)\n",
    "        # æ›´æ–°\n",
    "        self.num_correct += batch_correct\n",
    "        self.num_count += batch_count\n",
    "        \n",
    "    def accumulate(self):\n",
    "        # ä½¿ç”¨ç´¯è®¡çš„æ•°æ®ï¼Œè®¡ç®—æ€»çš„è¯„ä»·æŒ‡æ ‡\n",
    "        if self.num_count == 0:\n",
    "            return 0\n",
    "        return self.num_correct/self.num_count\n",
    "    \n",
    "    def reset(self):\n",
    "        self.num_correct = 0\n",
    "        self.num_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ©ç”¨ä¹‹å‰æ„é€ çš„æ•°æ®è¿›è¡Œæµ‹è¯•\n",
    "acc = Accuracy()\n",
    "acc.update(y_hat, y)\n",
    "acc.num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®ç°ç¬¬äºŒä¸ªè¾…åŠ©åŠŸèƒ½â€”â€”ä¸€ä¸ªæ•´åˆäº†è®­ç»ƒè¿‡ç¨‹çš„ç±»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner(object):\n",
    "    def __init__(self, model, optimizer, loss_fn, metric, **kwargs):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        # ç”¨äºè®¡ç®—è¯„ä»·æŒ‡æ ‡\n",
    "        self.metric = metric\n",
    "        \n",
    "        # è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯„ä»·æŒ‡æ ‡å˜åŒ–\n",
    "        self.dev_scores = []\n",
    "        # è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å˜åŒ–\n",
    "        self.train_epoch_losses = []\n",
    "        self.dev_losses = []\n",
    "        # è®°å½•å…¨å±€æœ€ä¼˜è¯„ä»·æŒ‡æ ‡\n",
    "        self.best_score = 0\n",
    "   \n",
    " \n",
    "# æ¨¡å‹è®­ç»ƒé˜¶æ®µ\n",
    "    def train(self, train_loader, dev_loader=None, **kwargs):\n",
    "        # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œæ­¤æ—¶æ¨¡å‹çš„å‚æ•°ä¼šè¢«æ›´æ–°\n",
    "        self.model.train()\n",
    "        \n",
    "        num_epochs = kwargs.get('num_epochs', 0)\n",
    "        log_steps = kwargs.get('log_steps', 100)\n",
    "        save_path = kwargs.get('save_path','best_mode.pth')\n",
    "        eval_steps = kwargs.get('eval_steps', 0)\n",
    "        # è¿è¡Œçš„stepæ•°ï¼Œä¸ç­‰äºepochæ•°\n",
    "        global_step = 0\n",
    "        \n",
    "        if eval_steps:\n",
    "            if dev_loader is None:\n",
    "                raise RuntimeError('Error: dev_loader can not be None!')\n",
    "            if self.metric is None:\n",
    "                raise RuntimeError('Error: Metric can not be None')\n",
    "                \n",
    "        # éå†è®­ç»ƒçš„è½®æ•°\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            # éå†æ•°æ®é›†\n",
    "            for step, data in enumerate(train_loader):\n",
    "                x, y = data\n",
    "                logits = self.model(x.float())\n",
    "                loss = self.loss_fn(logits, y.long())\n",
    "                total_loss += loss\n",
    "                if log_steps and global_step%log_steps == 0:\n",
    "                    print(f'loss:{loss.item():.5f}')\n",
    "                    \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            # æ¯éš”ä¸€å®šè½®æ¬¡è¿›è¡Œä¸€æ¬¡éªŒè¯ï¼Œç”±eval_stepså‚æ•°æ§åˆ¶ï¼Œå¯ä»¥é‡‡ç”¨ä¸åŒçš„éªŒè¯åˆ¤æ–­æ¡ä»¶\n",
    "            if (epoch+1)% eval_steps ==  0:\n",
    "\n",
    "                dev_score, dev_loss = self.evaluate(dev_loader, global_step=global_step)\n",
    "                print(f'[Evalute] dev score:{dev_score:.5f}, dev loss:{dev_loss:.5f}')\n",
    "                \n",
    "                if dev_score > self.best_score:\n",
    "                    self.save_model(f'model_{epoch+1}.pth')\n",
    "                    \n",
    "                    print(f'[Evaluate]best accuracy performance has been updated: {self.best_score:.5f}-->{dev_score:.5f}')\n",
    "                    self.best_score = dev_score\n",
    "                    \n",
    "                # éªŒè¯è¿‡ç¨‹ç»“æŸåï¼Œè¯·è®°ä½å°†æ¨¡å‹è°ƒå›è®­ç»ƒæ¨¡å¼   \n",
    "                self.model.train()\n",
    "            \n",
    "            global_step += 1\n",
    "            # ä¿å­˜å½“å‰è½®æ¬¡è®­ç»ƒæŸå¤±çš„ç´¯è®¡å€¼\n",
    "            train_loss = (total_loss/len(train_loader)).item()\n",
    "            self.train_epoch_losses.append((global_step,train_loss))\n",
    "            \n",
    "        print('[Train] Train done')\n",
    "        \n",
    "    # æ¨¡å‹è¯„ä»·é˜¶æ®µ\n",
    "    def evaluate(self, dev_loader, **kwargs):\n",
    "        assert self.metric is not None\n",
    "        # å°†æ¨¡å‹è®¾ç½®ä¸ºéªŒè¯æ¨¡å¼ï¼Œæ­¤æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹çš„å‚æ•°ä¸ä¼šæ›´æ–°\n",
    "        self.model.eval()\n",
    "        global_step = kwargs.get('global_step',-1)\n",
    "        total_loss = 0\n",
    "        self.metric.reset()\n",
    "        \n",
    "        for batch_id, data in enumerate(dev_loader):\n",
    "            x, y = data\n",
    "            logits = self.model(x.float())\n",
    "            loss = self.loss_fn(logits, y.long()).item()\n",
    "            total_loss += loss \n",
    "            self.metric.update(logits, y)\n",
    "            \n",
    "        dev_loss = (total_loss/len(dev_loader))\n",
    "        self.dev_losses.append((global_step, dev_loss))\n",
    "        dev_score = self.metric.accumulate()\n",
    "        self.dev_scores.append(dev_score)\n",
    "        return dev_score, dev_loss\n",
    "    \n",
    "    # æ¨¡å‹é¢„æµ‹é˜¶æ®µï¼Œ\n",
    "    def predict(self, x, **kwargs):\n",
    "        self.model.eval()\n",
    "        logits = self.model(x)\n",
    "        return logits\n",
    "    \n",
    "    # ä¿å­˜æ¨¡å‹çš„å‚æ•°\n",
    "    def save_model(self, save_path):\n",
    "        torch.save(self.model.state_dict(),save_path)\n",
    "        \n",
    "    # è¯»å–æ¨¡å‹çš„å‚æ•°\n",
    "    def load_model(self, model_path):\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "output_size = 3\n",
    "hidden_size = 6\n",
    "# å®šä¹‰æ¨¡å‹\n",
    "model = FeedForward(input_size, hidden_size, output_size)\n",
    "# å®šä¹‰æŸå¤±å‡½æ•°\n",
    "loss_fn = F.cross_entropy\n",
    "# å®šä¹‰ä¼˜åŒ–å™¨\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2)\n",
    "# å®šä¹‰è¯„ä»·æ–¹æ³•\n",
    "metric = Accuracy(is_logist=True)\n",
    "# å®ä¾‹åŒ–è¾…åŠ©runnerç±»\n",
    "runner = Runner(model, optimizer, loss_fn, metric)\n",
    "# æ¨¡å‹è®­ç»ƒ\n",
    "runner.train(train_loader, dev_loader, num_epochs=50, log_steps=10, eval_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒRunnerç±»è®°å½•äº†æ¯æ¬¡è¿­ä»£åçš„æŸå¤±å‡½æ•°å€¼å’Œå‡†ç¡®ç‡(åœ¨ä¸åŒè®¾ç½®ä¸‹ï¼Œè®°å½•çš„é¢‘ç‡ä¼šæœ‰æ‰€ä¸åŒ)ï¼Œå¯è§†åŒ–å‡½æ•°åˆ©ç”¨è¿™äº›è®°å½•ï¼Œç»˜åˆ¶å›¾åƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»˜åˆ¶è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æŸå¤±å˜åŒ–ä»¥åŠéªŒè¯é›†ä¸Šçš„å‡†ç¡®ç‡å˜åŒ–æ›²çº¿\n",
    "def plot_training_loss_acc(runner, fig_name, fig_size=(16, 6), sample_step=20, loss_legend_loc='upper right', acc_legend_loc='lower right',\n",
    "                          train_color = '#8E004D', dev_color = '#E20079', fontsize='x-large', train_linestyle='-', dev_linestyle='--'):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.subplot(1,2,1)\n",
    "    train_items = runner.train_epoch_losses[::sample_step]\n",
    "    train_steps = [x[0] for x in train_items]\n",
    "    train_losses = [x[1] for x in train_items]\n",
    "    \n",
    "    plt.plot(train_steps, train_losses, color=train_color, linestyle=train_linestyle, label='Train loss')\n",
    "    if len(runner.dev_losses) > 0:\n",
    "        dev_steps = [x[0] for x in runner.dev_losses]\n",
    "        dev_losses = [x[1] for x in runner.dev_losses]\n",
    "        plt.plot(dev_steps, dev_losses, color=dev_color, linestyle=dev_linestyle,label='dev loss')\n",
    "    \n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('step')\n",
    "    plt.legend(loc=loss_legend_loc)\n",
    "    if len(runner.dev_scores) > 0:\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(dev_steps, runner.dev_scores, color=dev_color, linestyle=dev_linestyle, label='dev accuracy')\n",
    "        \n",
    "        plt.ylabel('score')\n",
    "        plt.xlabel('step')\n",
    "        plt.legend(loc=acc_legend_loc)\n",
    "    # å°†ç»˜åˆ¶ç»“æœä¿å­˜\n",
    "    plt.savefig(fig_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è°ƒç”¨ç»˜å›¾å‡½æ•°ï¼Œå°†runnerä¸­çš„ä¿¡æ¯ç»˜åˆ¶å¹¶ä¿å­˜\n",
    "plot_training_loss_acc(runner, 'chapter4.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é¢„æµ‹é˜¶æ®µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒç»“æŸåï¼Œç½‘ç»œçš„å‚æ•°ä¼šè‡ªåŠ¨ä¿å­˜ä¸º.pthç»“å°¾çš„æ–‡ä»¶ï¼Œä¸”ä¸è®­ç»ƒæ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹\n",
    "model_path = 'model_25.pth'\n",
    "# é¦–å…ˆè¯»å…¥ç»è¿‡è®­ç»ƒåçš„ç½‘ç»œçš„å‚æ•°\n",
    "runner.load_model(model_path)\n",
    "x, label= next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   è¯·åˆ†æä¸€ä¸‹é¢„æµ‹ç»“æœï¼Œè¾“å‡ºçš„ä¸‰ä¸ªæ•°å­—åˆ†åˆ«ä»£è¡¨ä¸‰ä¸ªç±»çš„å¾—åˆ†ï¼Œæ¨¡å‹è®¤ä¸ºæœ€åä¸€ç±»å¾—åˆ†æœ€é«˜ï¼Œå³è¾“å…¥ç‰¹å¾å¯¹åº”ä¸ºæœ€åä¸€ç±»ï¼Œä¸æ ‡ç­¾å€¼å»åˆã€‚\n",
    "    åœ¨æ„å»ºæµ‹è¯•é›†çš„DataLoaderç±»æ—¶ï¼Œæˆ‘ä»¬è®¾ç½®shuffleä¸ºTrueï¼Œæ‰€ä»¥å¯ä»¥å¤šæ¬¡å°è¯•é¢„æµ‹ä¸åŒçš„ç»“æœå¹¶ä¸æ ‡ç­¾å€¼å¯¹æ¯”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runner.predict(x.float()))\n",
    "print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9ccd8639d7ac6d8ae46f08631d02de0d1c9f4a08850208985333be71082afd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3 Experiment\n",
    "1. `Utilizing Numpy to implement Linear model and define loss function and computing loss value`\n",
    "2. `Utilizing Numpy to implement Softmax model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. import numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. define model\n",
    "$$\n",
    "f(x) = w*x+b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(x):\n",
    "    w = np.random.randn(1)\n",
    "    b = np.random.randn(1)\n",
    "    output = np.dot(x,w) + b\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. define the loss function \n",
    "$$\n",
    "Loss = (prediction - y)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y,prediction):\n",
    "    loss = (prediction - y) * (prediction - y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. define the data x and label y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is as follows:\n",
      "Item 0 x: 0.6325919738112332 y: 1.0\n",
      "Item 1 x: 0.8145836886693093 y: -1.0\n",
      "Item 2 x: 0.8162350946692772 y: 1.0\n",
      "Item 3 x: 0.7272743400268922 y: -1.0\n",
      "Item 4 x: 0.6563160337124457 y: 1.0\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(5,1)\n",
    "y = np.array([1,-1,1,-1,1]).astype('float')\n",
    "print (\"The data is as follows:\")\n",
    "for i in range(x.shape[0]):\n",
    "    print(\"Item \"+str(i),\"x:\",x[i][0],\"y:\",y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The all loss value is:\n",
      "Item 0 Loss: 2.8967061940406174\n",
      "Item 1 Loss: 0.001088374639046893\n",
      "Item 2 Loss: 4.145272448307004\n",
      "Item 3 Loss: 0.01582911850070681\n",
      "Item 4 Loss: 3.045451653851336\n"
     ]
    }
   ],
   "source": [
    "prediction = linear_model(x)\n",
    "loss = loss_function(y,prediction)\n",
    "print(\"The all loss value is:\")\n",
    "for i in range(len(loss)):\n",
    "    print(\"Item\",str(i),\"Loss:\",loss[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(inputs):\n",
    "    '''\n",
    "    please refer the content of nndl book and the above example code\n",
    "    '''\n",
    "    denominator = 0.0\n",
    "    for x in inputs:\n",
    "        denominator += np.exp(x)\n",
    "    output = []\n",
    "    for x in inputs:\n",
    "        numerator = np.exp(x)\n",
    "        prob = numerator / denominator\n",
    "        output.append(prob)\n",
    "    # Returns the indices of the maximum value of all elements\n",
    "    prediction = np.argmax(output)\n",
    "    return output, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The softmax probability: [0.2908589361060827, 0.19925787513384263, 0.19343708104831284, 0.1900465005912344, 0.12639960712052747]\n",
      "The argmax return value: 0\n"
     ]
    }
   ],
   "source": [
    "out, pred = softmax(np.random.rand(5))\n",
    "print(\"The softmax probability:\", out)\n",
    "print(\"The argmax return value:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please utilize PyTorch to implement the above experiments\n",
    "Attention:\n",
    "1. The code logic is the same as the above NumPy code. Therefore, you should understand the above NumPy code, and search the corresponding PyTorch API to rewrite the experiments.\n",
    "2. Related PyTorch APIs that you might use are as follows:\n",
    "    * random init tensor: `torch.rand()`, `torch.randn()`, `torch.randint()`\n",
    "    * matrix multiplication: `torch.mm()`, `torch.dot()`(Be carefull!)\n",
    "    * exponential operation: `torch.exp()`\n",
    "    * Returns the indices of the maximum value: `torch.argmax()`\n",
    "3. For a more detailed API please refer to: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is as follows:\n",
      "Item 0 x: 0.45031052827835083 y: 1.0\n",
      "Item 1 x: 0.6587034463882446 y: -1.0\n",
      "Item 2 x: 0.5067180395126343 y: 1.0\n",
      "Item 3 x: 0.10800302028656006 y: -1.0\n",
      "Item 4 x: 0.877412736415863 y: 1.0\n",
      "The all loss value is:\n",
      "Item 0 Loss: 0.05354660004377365\n",
      "Item 1 Loss: 3.771352529525757\n",
      "Item 2 Loss: 0.03402775153517723\n",
      "Item 3 Loss: 2.201582908630371\n",
      "Item 4 Loss: 0.01537090353667736\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Rewrite the code for Experiment 1\n",
    "'''\n",
    "import torch\n",
    "\n",
    "def linear_model(x):\n",
    "    w = torch.randn(1, 1)\n",
    "    b = torch.randn(1)\n",
    "    output = torch.mm(x, w) + b\n",
    "    return output\n",
    "\n",
    "def loss_function(y, prediction):\n",
    "    loss = (prediction - y) ** 2\n",
    "    return loss\n",
    "\n",
    "x = torch.rand(5,1)\n",
    "y = torch.tensor([1,-1,1,-1,1]).float().view(-1, 1)\n",
    "print (\"The data is as follows:\")\n",
    "for i in range(x.shape[0]):\n",
    "    print(\"Item \"+str(i),\"x:\",x[i][0].item(),\"y:\",y[i][0].item())\n",
    "\n",
    "prediction = linear_model(x)\n",
    "loss = loss_function(y, prediction)\n",
    "print(\"The all loss value is:\")\n",
    "for i in range(len(loss)):\n",
    "    print(\"Item\", str(i), \"Loss:\", loss[i][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Rewrite the code for Experiment 2\n",
    "'''\n",
    "import torch\n",
    "\n",
    "def softmax(inputs):\n",
    "    '''\n",
    "    please refer the content of nndl book and the above example code\n",
    "    '''\n",
    "    denominator = torch.sum(torch.exp(inputs))\n",
    "    output = torch.exp(inputs) / denominator\n",
    "    # Returns the indices of the maximum value of all elements\n",
    "    prediction = torch.argmax(output)\n",
    "    return output, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The softmax probability: tensor([0.1856, 0.2132, 0.1995, 0.1596, 0.2421])\n",
      "The argmax return value: tensor(4)\n"
     ]
    }
   ],
   "source": [
    "out, pred = softmax(torch.rand(5))\n",
    "print(\"The softmax probability:\", out)\n",
    "print(\"The argmax return value:\", pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "a00d112fbb29c8738e464c8151607ee4f23e594ae4ace070b7bc263386630dd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
